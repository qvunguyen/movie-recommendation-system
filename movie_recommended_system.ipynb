{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Import required libraries and load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "ratings = pd.read_csv('data/ratings.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Prepare the data for collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the scikit-surprise library, we'll create a dataset object and split the data into a train and test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build a collaborative filtering model\n",
    "\n",
    "We'll use the SVD algorithm to make movie recommendations based on collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7777  0.7779  0.7773  0.7778  0.7777  0.7777  0.0002  \n",
      "MAE (testset)     0.5866  0.5869  0.5865  0.5869  0.5865  0.5867  0.0002  \n",
      "Fit time          294.01  5609.21 501.17  4167.51 3482.13 2810.81 2087.63 \n",
      "Test time         952.00  4490.50 608.83  3210.54 6241.48 3100.67 2127.65 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.77766929, 0.77790203, 0.77733974, 0.77776941, 0.77765096]),\n",
       " 'test_mae': array([0.5865782 , 0.58685871, 0.58649324, 0.58687172, 0.58646588]),\n",
       " 'fit_time': (294.00930404663086,\n",
       "  5609.209953069687,\n",
       "  501.1718888282776,\n",
       "  4167.514079093933,\n",
       "  3482.1269397735596),\n",
       " 'test_time': (952.0028901100159,\n",
       "  4490.501410961151,\n",
       "  608.8305280208588,\n",
       "  3210.5446338653564,\n",
       "  6241.480406761169)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Prepare the data for content-based filtering\n",
    "To perform content-based filtering, we need to transform the movie genres into a feature vector using the TF-IDF approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Create a function for content-based recommendations\n",
    "This function takes a movie title as input and returns the top n similar movies based on the genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()\n",
    "\n",
    "def content_based_recommendations(title, n=10):\n",
    "    index = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies['title'].iloc[movie_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Combine collaborative and content-based filtering\n",
    "Create a hybrid recommendation function that takes a user ID and movie title as input, and outputs a list of top n recommended movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load links.csv file from the MovieLens dataset\n",
    "links = pd.read_csv('data/links.csv')\n",
    "\n",
    "# Convert the 'tmdbId' to integer and drop rows with missing values\n",
    "links = links.dropna(subset=['tmdbId'])\n",
    "links['tmdbId'] = links['tmdbId'].astype(int)\n",
    "\n",
    "# Merge the MovieLens and TMDB datasets using 'movieId' column\n",
    "movies = movies.merge(links, left_on='movieId', right_on='movieId')\n",
    "\n",
    "# Merge the movies dataset with the ratings dataset\n",
    "movies_with_ratings = movies.merge(ratings, on='movieId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations(user_id, title, n=10):\n",
    "    content_based = content_based_recommendations(title, n).to_frame()\n",
    "    content_based.columns = ['title']\n",
    "    content_based = content_based.merge(movies_with_ratings, on='title')\n",
    "    content_based = content_based.drop_duplicates(subset=['title'], keep='first')\n",
    "    content_based['est'] = content_based['movieId'].apply(lambda x: svd.predict(user_id, x).est)\n",
    "    content_based = content_based.sort_values('est', ascending=False)\n",
    "    return content_based.head(n)['title']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Testing recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for User 1 who likes 'Toy Story (1995)':\n",
      "1097                                        Traffic (2000)\n",
      "0                                       Mighty, The (1998)\n",
      "18439    Godzilla vs. Destroyah (Gojira vs. Desutoroi√¢)...\n",
      "908                                 Daddy Long Legs (1919)\n",
      "18550                                    Stagecoach (1966)\n",
      "18191                            Down in the Valley (2005)\n",
      "18120                             Hell Up in Harlem (1973)\n",
      "1053     Hatchet for the Honeymoon (Rosso segno della f...\n",
      "18138                                      Airborne (1993)\n",
      "18478                           The Alphabet Killer (2008)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "title = 'Toy Story (1995)'\n",
    "n = 10\n",
    "recommendations = hybrid_recommendations(user_id, title, n)\n",
    "print(f\"Top {n} recommendations for User {user_id} who likes '{title}':\")\n",
    "print(recommendations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
